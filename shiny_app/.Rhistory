charsToClean <- c("[:cntrl:]", "[:punct:]")
for (i in 1:length(charsToClean))
inputText <- gsub(paste0("[", charsToClean[i], "]"),  " ", inputText, fixed=FALSE)
inputText
}
# Break an input text in x-grams, i.e. the last n-1 words of the corresponding n-grams.
# Returns list of x-grams.
makeXgrams <- function(inputText, ngramRange=1:4) {
dmessage("makeXgrams")
inputText <- cleanInput(inputText)
xgramRange <- (ngramRange - 1)
xgramRange <- xgramRange[xgramRange > 0]
xgrams <- lapply(xgramRange, function(n) {
if (n > 0) {
# xgram regex matches 1 .. n-1 words
xgram <- regmatches(inputText, regexec(paste0("^.*\\b(", paste(rep("\\w+ +", n-1), collapse=""), "\\w+) *$"), inputText))
dmessage("xgram: ", xgram)
# drop first element, which contains the entire inputText, keeping only the n words part
xgram[[1]][-1]
}
else character(0)
})
xgrams
}
# Predict the next words for all x-grams in an input text, based on a given set of n-grams, n in range 1:4
# Returns best candidates for the next word, as a data frame with columns predict (the predicted word) and total.freq (the observed
# total nr of occurrences of the n-grams predicting the best candidates)
predictN <- function(inputText, nglist, ngramRange=1:4, order="freq", reorderThreshold=0) {
# inputText = predictor text
# ngrams = ordered list of ngrams, n-th item in list is data frame of n-grams (columns ngram and total.freq)
dmessage("predictN")
dmessage("inputText: ", inputText)
dprint(str(nglist))
# Predict using longest ending ngram, if no match fall back to longest ngram minus 1, etc.
# If 2-gram fails, predict single word with highest probability in directionary.
xgrams <- makeXgrams(inputText, ngramRange)
dprint(xgrams)
# apply xgrams in reverse order (highest n first) to find potential candidates
candidates <- ldply(length(xgrams):1, function(x) {
# lookup x in n+1-grams
ng <- nglist[[x+1]]
if (order=="ml") ng <- ng[order(-ng$ml),]
cands <- head(ng[ng$xgram == xgrams[[x]], c("predict", "freq", "ml")])
cands$n <- rep(x+1, nrow(cands))
cands
})
# if no candidates found using higher-level ngrams, use 1-gram
if (nrow(candidates) == 0) {
candidates <- head(nglist[[1]])
candidates$n <- 1
}
# remove duplicates
# because of the data frame's descending order of frequency,
# duplicated() will remove the lower frequency duplicated items
candidates[,"dup"] <- ifelse(duplicated(candidates$predict), TRUE, FALSE)
#     # reorder by global frequency
#     # if digits(max(total.freq)) for highest n-gram is within threshold digits(max(total.freq)) for lower order n-grams
#     freq.max <- sapply(2:3, function(n) max(candidates[candidates$n == n, "freq"]))
#     if (min(nchar(freq.max)) + reorderThreshold >= max(nchar(freq.max)))
#         candidates <- candidates[order(-candidates$freq),]
dprint(str(candidates))
dprint(candidates)
candidates$ngram <- NULL
candidates
}
# ---
# title:  "Next Word Prediction Using N-Grams (Good-Turing Smoothing)"
# subtitle:   "Data Science Capstone Final Project Report"
# author: "Amit Man Singh"
# date:   "2016-05-30"
# ---
# ui.R
source("sharedheader.R")
library(shiny)
shinyUI(fluidPage(theme="style.css",
titlePanel("Predicting Next Word Using N-Grams (Good-Turing Smoothing)"),
sidebarLayout(
sidebarPanel(width=4,
h3("Application Introduction"),
p("This app predicts the next English word of a sentence, using an n-gram based text prediction model with smoothing. It is what you see while typing in your Smartphones!"),
p("Start typing your sentence in the text box. When you finish typing the predicted next word is displayed immediately."),
p("There is also a cloud of words drawn that shows the collection of other near matches of prediction"),
p("If the show other probabal words is true, details is shown with word cloud. Else just the next word is shown."),
p(tags$a(href = "http://www.ngrams.info/download_coca.asp", "For data on Ngrams")),
HTML("<br/><br/>"),
#p("Text Prediction Model Status:",textOutput("model.status",inline=TRUE)),
#selectInput("tssample", "Select training sample percentage:", tslist, multiple=FALSE, selected=tslist.selected),
fluidRow(
#column(3,
#       p("Training data size:", textOutput("ng.size", inline=TRUE))
#       )
#column(9,
#       span("Load time: ", HTML("<span style='font-size:small;'>(Please allow for up to 15 seconds)</span>"), htmlOutput("ng.loadtime"))
#       )
),
#p("Size:", textOutput("ng.size", inline = TRUE)),
#span("Load time (sec):", htmlOutput("ng.loadtime")),
#HTML("<br/>"), p("Prediction time:", textOutput("ng.predtime", inline=TRUE)),
#HTML("<br/>"),
radioButtons("showcandidates", "Show other probabal words:", c("True", "False"), selected="True", inline = TRUE),
HTML("<br/><br/>"),
p("Training set data:", textOutput("ngrams.info1", inline=TRUE)),
tableOutput("ngrams.info2")
),
mainPanel(width = 8,
column(5,
HTML("<br>"),
strong(p("Enter your text:", style="margin-bottom:-10px;")),
textInput("inputtext", label="", value="I love"),
HTML("<br>"),
p("You typed:"),
#HTML("<div style='padding-left:10px; height:30px;'>"),
HTML("<em>"), textOutput("inputecho"), HTML("</em>"),
#HTML("</div>"),
HTML("<br>"),
p("The suggested next word is:"),
#HTML("<div style='padding-left:10px; height:30px; font-weight:bold;'"),
strong(textOutput("prediction")),
#HTML("</div>"),
HTML("<br><br>"),
conditionalPanel(condition = "input.showcandidates == 'True'",
p("Cloud of probabal words :"),
plotOutput("ngrams.info3", height=500)
)
),
column(6, offset=1,
fluidRow(
conditionalPanel(condition = "input.showcandidates == 'True'",
fluidRow(
p("As selected from the following words:"),
tableOutput("candidates")
)
)
)
)
)
) #sidebarLayout
)) # fluidPage shinyUI
# ---
# title:  "Next Word Prediction Using N-Grams (Good-Turing Smoothing)"
# subtitle:   "Data Science Capstone Final Project Report"
# author: "Amit Man Singh"
# date:   "2016-05-30"
# ---
# server.R
#
source("sharedheader.R")
source("predict.R")
library(shiny)
library(plyr)
library(Rcpp)
library(RColorBrewer)
library(wordcloud)
values <- reactiveValues(load.time=NULL, pred.time=NULL)
shinyServer(function(input, output, session) {
ng <- reactive({
#ng.status<-c("Loading ...")
fileNgrams <- paste0("ngrams ", "5.00", ".rds")
#validate(
#need(any(input$tssample %in% tslist), "Please select training set."),
#   need(file.exists(fileNgrams), "File not found.")
#)
message("readRDS: ", fileNgrams)
load.time <- system.time({
ng <- readRDS(file = fileNgrams)
#model.status<-c("Completed :)")
})
#values$load.time <- HTML(paste0("<table width='100%'><tr><td width='33%'>user</td><td width='33%'>system</td><td width='33%'>elapsed</td></tr>", sprintf("<tr><td>%3.2f s</td><td>%3.2f s</td><td>%3.2f s</td></tr></table>", load.time[1], load.time[2], load.time[3])))
ng
})
#output$ng.size <- reactive({
#    if (is.null(ng)) { return(NULL) }
#    ng.size <- sprintf("%.1f MB", object.size(ng())[1]/(2^20))
#    ng.size
#})
output$ng.loadtime <- reactive({
values$load.time
})
output$ng.predtime <- reactive({
values$pred.time
})
output$ngrams.info1 <- renderText({
if (is.null(ng())) return("Loading ... ")
ng()$scenario
})
output$ngrams.info2 <- renderTable({
if (is.null(ng())) return(NULL)
do.call("cbind", ldply(1:4, function(n) data.frame(n=n, n.grams=nrow(ng()[[n]]))))
}, include.rownames=FALSE)
output$ngrams.info3 <- renderPlot({
if (is.null(ng())) return(NULL)
wc.data <- predictN(input$inputtext, ng(), ngramRange = 1:4)
wc.data <- wc.data[!wc.data$dup, c("predict", "ml", "n")]
# normalize ml value to range 1 .. 100
wc.data$ml <- as.numeric(wc.data$ml)
suppressWarnings(
ml.min <- min(wc.data$ml, na.rm=TRUE)
)
if (ml.min == Inf) {
# all values are missing
wc.data$ml <- 100
} else {
wc.data$ml <- ifelse(is.na(wc.data$ml), ml.min, wc.data$ml)
ml.max <- max(wc.data$ml)
wc.data$ml <- wc.data$ml / ml.max * 100
}
# compress range for better readability of word cloud image
wc.data$ml <- round(log(wc.data$ml), 0)
#pal <- brewer.pal(4, "Set2")
wordcloud(wc.data$predict, wc.data$ml, scale=c(2,.2), min.freq=0, max.words=Inf,
random.order=FALSE, random.color=FALSE,
rot.per=.1, colors=wc.data$n, ordered.colors=TRUE, use.r.layout=FALSE, fixed.asp=TRUE)
})
output$inputecho <- reactive({
input$inputtext
})
candidates <- reactive({
if (is.null(ng)) { return(NULL) }
pred.time <- system.time({
candidates <- predictN(input$inputtext, ng(), ngramRange = 1:4)
})
values$pred.time <- HTML(sprintf("%3.2f s", pred.time[3]))
candidates
})
output$candidates <- renderTable({
candidates()[, c("predict", "freq", "ml", "n")]
}
, display = c("d", "s", "d", "f", "d"), include.rownames=FALSE
)
output$prediction <- renderText({
candidates()[1, "predict"]
})
})
setwd("~/capstone_final/shiny_app")
# ---
# title:  "Next Word Prediction Using N-Grams (Good-Turing Smoothing)"
# subtitle:   "Data Science Capstone Final Project Report"
# author: "Amit Man Singh"
# date:   "2016-05-30"
# ---
# predict.R
#
# prediction functions
cleanInput <- function(inputText) {
dmessage("cleanInput")
# remove single quotes, don't ==> dont
inputText <- gsub("'", "", tolower(inputText), fixed=TRUE)
# remove non-word charactters
charsToClean <- c("[:cntrl:]", "[:punct:]")
for (i in 1:length(charsToClean))
inputText <- gsub(paste0("[", charsToClean[i], "]"),  " ", inputText, fixed=FALSE)
inputText
}
# Break an input text in x-grams, i.e. the last n-1 words of the corresponding n-grams.
# Returns list of x-grams.
makeXgrams <- function(inputText, ngramRange=1:4) {
dmessage("makeXgrams")
inputText <- cleanInput(inputText)
xgramRange <- (ngramRange - 1)
xgramRange <- xgramRange[xgramRange > 0]
xgrams <- lapply(xgramRange, function(n) {
if (n > 0) {
# xgram regex matches 1 .. n-1 words
xgram <- regmatches(inputText, regexec(paste0("^.*\\b(", paste(rep("\\w+ +", n-1), collapse=""), "\\w+) *$"), inputText))
dmessage("xgram: ", xgram)
# drop first element, which contains the entire inputText, keeping only the n words part
xgram[[1]][-1]
}
else character(0)
})
xgrams
}
# Predict the next words for all x-grams in an input text, based on a given set of n-grams, n in range 1:4
# Returns best candidates for the next word, as a data frame with columns predict (the predicted word) and total.freq (the observed
# total nr of occurrences of the n-grams predicting the best candidates)
predictN <- function(inputText, nglist, ngramRange=1:4, order="freq", reorderThreshold=0) {
# inputText = predictor text
# ngrams = ordered list of ngrams, n-th item in list is data frame of n-grams (columns ngram and total.freq)
dmessage("predictN")
dmessage("inputText: ", inputText)
dprint(str(nglist))
# Predict using longest ending ngram, if no match fall back to longest ngram minus 1, etc.
# If 2-gram fails, predict single word with highest probability in directionary.
xgrams <- makeXgrams(inputText, ngramRange)
dprint(xgrams)
# apply xgrams in reverse order (highest n first) to find potential candidates
candidates <- ldply(length(xgrams):1, function(x) {
# lookup x in n+1-grams
ng <- nglist[[x+1]]
if (order=="ml") ng <- ng[order(-ng$ml),]
cands <- head(ng[ng$xgram == xgrams[[x]], c("predict", "freq", "ml")])
cands$n <- rep(x+1, nrow(cands))
cands
})
# if no candidates found using higher-level ngrams, use 1-gram
if (nrow(candidates) == 0) {
candidates <- head(nglist[[1]])
candidates$n <- 1
}
# remove duplicates
# because of the data frame's descending order of frequency,
# duplicated() will remove the lower frequency duplicated items
candidates[,"dup"] <- ifelse(duplicated(candidates$predict), TRUE, FALSE)
#     # reorder by global frequency
#     # if digits(max(total.freq)) for highest n-gram is within threshold digits(max(total.freq)) for lower order n-grams
#     freq.max <- sapply(2:3, function(n) max(candidates[candidates$n == n, "freq"]))
#     if (min(nchar(freq.max)) + reorderThreshold >= max(nchar(freq.max)))
#         candidates <- candidates[order(-candidates$freq),]
dprint(str(candidates))
dprint(candidates)
candidates$ngram <- NULL
candidates
}
# ---
# title:  "Next Word Prediction Using N-Grams (Good-Turing Smoothing)"
# subtitle:   "Data Science Capstone Final Project Report"
# author: "Amit Man Singh"
# date:   "2016-05-30"
# ---
# ui.R
source("sharedheader.R")
library(shiny)
shinyUI(fluidPage(theme="style.css",
titlePanel("Predicting Next Word Using N-Grams (Good-Turing Smoothing)"),
sidebarLayout(
sidebarPanel(width=4,
h3("Application Introduction"),
p("This app predicts the next English word of a sentence, using an n-gram based text prediction model with smoothing. It is what you see while typing in your Smartphones!"),
p("Start typing your sentence in the text box. When you finish typing the predicted next word is displayed immediately."),
p("There is also a cloud of words drawn that shows the collection of other near matches of prediction"),
p("If the show other probabal words is true, details is shown with word cloud. Else just the next word is shown."),
p(tags$a(href = "http://www.ngrams.info/download_coca.asp", "For data on Ngrams")),
HTML("<br/><br/>"),
#p("Text Prediction Model Status:",textOutput("model.status",inline=TRUE)),
#selectInput("tssample", "Select training sample percentage:", tslist, multiple=FALSE, selected=tslist.selected),
fluidRow(
#column(3,
#       p("Training data size:", textOutput("ng.size", inline=TRUE))
#       )
#column(9,
#       span("Load time: ", HTML("<span style='font-size:small;'>(Please allow for up to 15 seconds)</span>"), htmlOutput("ng.loadtime"))
#       )
),
#p("Size:", textOutput("ng.size", inline = TRUE)),
#span("Load time (sec):", htmlOutput("ng.loadtime")),
#HTML("<br/>"), p("Prediction time:", textOutput("ng.predtime", inline=TRUE)),
#HTML("<br/>"),
radioButtons("showcandidates", "Show other probabal words:", c("True", "False"), selected="True", inline = TRUE),
HTML("<br/><br/>"),
p("Training set data:", textOutput("ngrams.info1", inline=TRUE)),
tableOutput("ngrams.info2")
),
mainPanel(width = 8,
column(5,
HTML("<br>"),
strong(p("Enter your text:", style="margin-bottom:-10px;")),
textInput("inputtext", label="", value="I love"),
HTML("<br>"),
p("You typed:"),
#HTML("<div style='padding-left:10px; height:30px;'>"),
HTML("<em>"), textOutput("inputecho"), HTML("</em>"),
#HTML("</div>"),
HTML("<br>"),
p("The suggested next word is:"),
#HTML("<div style='padding-left:10px; height:30px; font-weight:bold;'"),
strong(textOutput("prediction")),
#HTML("</div>"),
HTML("<br><br>"),
conditionalPanel(condition = "input.showcandidates == 'True'",
p("Cloud of probabal words :"),
plotOutput("ngrams.info3", height=500)
)
),
column(6, offset=1,
fluidRow(
conditionalPanel(condition = "input.showcandidates == 'True'",
fluidRow(
p("As selected from the following words:"),
tableOutput("candidates")
)
)
)
)
)
) #sidebarLayout
)) # fluidPage shinyUI
# ---
# title:  "Next Word Prediction Using N-Grams (Good-Turing Smoothing)"
# subtitle:   "Data Science Capstone Final Project Report"
# author: " Amit Man Singh"
# date:   "2016-05-30"
# ---
# sharedheader.R
#
# debug print functions
dmessage <- function(...) if (mydebug) message(...)
dprint <- function(...) if (mydebug) print(...)
tslist <- c("0.30", "1.00", "5.00")
tslist.selected <- "1.00"
mydebug <- FALSE
# ---
# title:  "Next Word Prediction Using N-Grams (Good-Turing Smoothing)"
# subtitle:   "Data Science Capstone Final Project Report"
# author: "Amit Man Singh"
# date:   "2016-05-30"
# ---
# server.R
#
source("sharedheader.R")
source("predict.R")
library(shiny)
library(plyr)
library(Rcpp)
library(RColorBrewer)
library(wordcloud)
values <- reactiveValues(load.time=NULL, pred.time=NULL)
shinyServer(function(input, output, session) {
ng <- reactive({
#ng.status<-c("Loading ...")
fileNgrams <- paste0("ngrams ", "5.00", ".rds")
#validate(
#need(any(input$tssample %in% tslist), "Please select training set."),
#   need(file.exists(fileNgrams), "File not found.")
#)
message("readRDS: ", fileNgrams)
load.time <- system.time({
ng <- readRDS(file = fileNgrams)
#model.status<-c("Completed :)")
})
#values$load.time <- HTML(paste0("<table width='100%'><tr><td width='33%'>user</td><td width='33%'>system</td><td width='33%'>elapsed</td></tr>", sprintf("<tr><td>%3.2f s</td><td>%3.2f s</td><td>%3.2f s</td></tr></table>", load.time[1], load.time[2], load.time[3])))
ng
})
#output$ng.size <- reactive({
#    if (is.null(ng)) { return(NULL) }
#    ng.size <- sprintf("%.1f MB", object.size(ng())[1]/(2^20))
#    ng.size
#})
output$ng.loadtime <- reactive({
values$load.time
})
output$ng.predtime <- reactive({
values$pred.time
})
output$ngrams.info1 <- renderText({
if (is.null(ng())) return("Loading ... ")
ng()$scenario
})
output$ngrams.info2 <- renderTable({
if (is.null(ng())) return(NULL)
do.call("cbind", ldply(1:4, function(n) data.frame(n=n, n.grams=nrow(ng()[[n]]))))
}, include.rownames=FALSE)
output$ngrams.info3 <- renderPlot({
if (is.null(ng())) return(NULL)
wc.data <- predictN(input$inputtext, ng(), ngramRange = 1:4)
wc.data <- wc.data[!wc.data$dup, c("predict", "ml", "n")]
# normalize ml value to range 1 .. 100
wc.data$ml <- as.numeric(wc.data$ml)
suppressWarnings(
ml.min <- min(wc.data$ml, na.rm=TRUE)
)
if (ml.min == Inf) {
# all values are missing
wc.data$ml <- 100
} else {
wc.data$ml <- ifelse(is.na(wc.data$ml), ml.min, wc.data$ml)
ml.max <- max(wc.data$ml)
wc.data$ml <- wc.data$ml / ml.max * 100
}
# compress range for better readability of word cloud image
wc.data$ml <- round(log(wc.data$ml), 0)
#pal <- brewer.pal(4, "Set2")
wordcloud(wc.data$predict, wc.data$ml, scale=c(2,.2), min.freq=0, max.words=Inf,
random.order=FALSE, random.color=FALSE,
rot.per=.1, colors=wc.data$n, ordered.colors=TRUE, use.r.layout=FALSE, fixed.asp=TRUE)
})
output$inputecho <- reactive({
input$inputtext
})
candidates <- reactive({
if (is.null(ng)) { return(NULL) }
pred.time <- system.time({
candidates <- predictN(input$inputtext, ng(), ngramRange = 1:4)
})
values$pred.time <- HTML(sprintf("%3.2f s", pred.time[3]))
candidates
})
output$candidates <- renderTable({
candidates()[, c("predict", "freq", "ml", "n")]
}
, display = c("d", "s", "d", "f", "d"), include.rownames=FALSE
)
output$prediction <- renderText({
candidates()[1, "predict"]
})
})
source("sharedheader.R")
source("predict.R")
dmessage <- function(...) if (mydebug) message(...)
dprint <- function(...) if (mydebug) print(...)
tslist <- c("0.30", "1.00", "5.00")
tslist.selected <- "1.00"
mydebug <- FALSE
cleanInput <- function(inputText) {
dmessage("cleanInput")
# remove single quotes, don't ==> dont
inputText <- gsub("'", "", tolower(inputText), fixed=TRUE)
# remove non-word charactters
charsToClean <- c("[:cntrl:]", "[:punct:]")
for (i in 1:length(charsToClean))
inputText <- gsub(paste0("[", charsToClean[i], "]"),  " ", inputText, fixed=FALSE)
inputText
}
